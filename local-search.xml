<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>图像布局生成研究综述</title>
    <link href="/2025/08/18/%E5%9B%BE%E5%83%8F%E5%B8%83%E5%B1%80%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0/"/>
    <url>/2025/08/18/%E5%9B%BE%E5%83%8F%E5%B8%83%E5%B1%80%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="图像布局生成研究综述"><a href="#图像布局生成研究综述" class="headerlink" title="图像布局生成研究综述"></a>图像布局生成研究综述</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>​在自动化设计与人工智能生成内容（AIGC, Artificial Intelligence Generated Content）的快速发展背景下，<strong>图像布局生成（Image Layout Generation）</strong> 成为一个越来越重要的研究方向。所谓“布局”，指的是在一幅图像、页面或设计中，<strong>不同元素（如文本框、图片、按钮、广告位等）在空间中的排列与组合</strong>。<br>优秀的布局不仅影响美观性，还直接决定了信息传达效率与用户体验。  </p><p>​在现实应用中，图像布局生成有着极其广泛的场景：  </p><ul><li><strong>UI 设计与原型生成</strong>：自动为 APP 界面生成初始布局，帮助设计师快速迭代。  </li><li><strong>广告与海报排版</strong>：根据文字内容与图像素材自动排版，提高效率。  </li><li><strong>图文混排</strong>：如论文、杂志、网页中的自动排版。  </li><li><strong>文生图 pipeline</strong>：作为中间环节，先生成布局再细化生成高质量图像。</li></ul><p>​学术研究方面，过去几年涌现出几十篇相关论文，从 <strong>早期的VAE、GAN</strong>，到 <strong>Transformer</strong>、**扩散模型（Diffusion Models）**以及现在的多模态大模型，方法不断迭代。与此同时，输入输出的表达方式也在演变：从最初的简单几何参数，到结合文本描述、图像条件的多模态输入，再到面向自然语言的任务泛化。  </p><h2 id="发展脉络与时间线"><a href="#发展脉络与时间线" class="headerlink" title="发展脉络与时间线"></a>发展脉络与时间线</h2><p>​图像布局生成的发展大致可以分为四个阶段：</p><pre><code class=" mermaid">timeline    title 图像布局生成研究发展脉络    2019-2020 : VAE/GAN 阶段 : LayoutVAE, LayoutGAN    2021-2022 : Transformer 阶段 : BLT, LayoutTransformer    2023 : Diffusion 模型阶段 : DiffLayout, LayoutDM, LTSim    2024-至今 : 多模态与交互式生成 : LLM + Layout, Human-in-the-loop</code></pre><h2 id="核心论文对比表"><a href="#核心论文对比表" class="headerlink" title="核心论文对比表"></a>核心论文对比表</h2><h3 id="2019–2020：VAE、-GAN（开源）"><a href="#2019–2020：VAE、-GAN（开源）" class="headerlink" title="2019–2020：VAE、 GAN（开源）"></a>2019–2020：VAE、 GAN（开源）</h3><table><thead><tr><th align="center">论文</th><th align="center">年份</th><th align="center">Publisher</th><th align="center">模型结构</th><th align="center">输入</th><th align="center">输出</th><th align="center">创新点</th><th align="center">数据集</th></tr></thead><tbody><tr><td align="center">[LayoutGAN](####《LAYOUTGAN: GENERATING GRAPHIC LAYOUTS  WITH WIREFRAME DISCRIMINATORS》)</td><td align="center">2019</td><td align="center">ICLR</td><td align="center">GAN</td><td align="center">[n,c,x,y,w,h]（指定类别+随机噪声）</td><td align="center">[n,x,y,w,h]</td><td align="center">自注意力机制+可微分的wireframe渲染层+双重判别器网络</td><td align="center">MNIST、PublayNet</td></tr><tr><td align="center"><a href="">LayoutVAE</a></td><td align="center">2019</td><td align="center">ICCV</td><td align="center">VAE（Encoder+decoder）</td><td align="center">标签集 L ⊆ {1, 2, …, M}（物体类别）</td><td align="center">CountVAE输出每个类别的对象数量（例如，标签 1 的数量是 3），BBoxVAE 输出每个对象的边界框坐标（例如，x, y, w, h 值）。</td><td align="center"></td><td align="center">MNIST、COCO</td></tr><tr><td align="center">[Content-Aware Generative Modeling of Graphic Design Layouts](####《Content-Aware Generative Modeling of Graphic Design Layouts》)</td><td align="center">2019</td><td align="center">ACM TOG</td><td align="center">GAN+多模态嵌入网络</td><td align="center">图像集合（多个图像，每个图像通过卷积神经网络（CNN）进行编码提取特征）、关键词（从文本内容中提取的摘要，使用RAKE方法提取）、设计属性（包括设计类别、文本比例和图像比例）</td><td align="center">代表类别信息的单元格图像布局（60x45），6个类别，使用 3 维二进制向量进行编码</td><td align="center"></td><td align="center"></td></tr></tbody></table><h4 id="《LAYOUTGAN-GENERATING-GRAPHIC-LAYOUTS-WITH-WIREFRAME-DISCRIMINATORS》"><a href="#《LAYOUTGAN-GENERATING-GRAPHIC-LAYOUTS-WITH-WIREFRAME-DISCRIMINATORS》" class="headerlink" title="《LAYOUTGAN: GENERATING GRAPHIC LAYOUTS  WITH WIREFRAME DISCRIMINATORS》"></a>《LAYOUTGAN: GENERATING GRAPHIC LAYOUTS  WITH WIREFRAME DISCRIMINATORS》</h4><p>输入：N个布局元素，每个元素包含（c,x,y,w,h）， 输出：元素集合（c,x,y,w,h）</p><p>创新点：</p><ul><li><p>自注意力机制（Self-Attention）：在生成器中引入了自注意力机制，能够动态调整每个元素相对于其他元素的位置和关系，从而生成更合理和对齐的布局。</p></li><li><p>可微分的wireframe渲染层（Wireframe Rendering Layer）：为了有效优化布局生成过程，LayoutGAN引入了一个新型的可微分渲染层，将图形元素渲染为wireframe（线框图）。这种方式解决了传统方法中的渲染问题（例如重叠和遮挡），因为wireframe渲染能够确保即使在元素之间存在遮挡，模型也能正确地进行反向传播，从而进行有效的优化。</p></li><li><p>双重判别器网络：LayoutGAN使用了两个不同的判别器网络来评估生成的布局。第一个判别器基于元素的类概率和几何参数，评估元素之间的关系。第二个判别器是基于视觉域的，它通过wireframe渲染层生成的图像来优化布局的对齐性和一致性。</p></li></ul><p>任务类型：类别-&gt;位置＋尺寸</p><h4 id="《LayoutVAE-Stochastic-Scene-Layout-Generation-From-a-Label-Set》"><a href="#《LayoutVAE-Stochastic-Scene-Layout-Generation-From-a-Label-Set》" class="headerlink" title="《LayoutVAE: Stochastic Scene Layout Generation From a Label Set》"></a>《LayoutVAE: Stochastic Scene Layout Generation From a Label Set》</h4><p><strong>输入</strong>：标签集合（L，包含图像中所有物体的类别），CountVAE 接收标签集合并生成每个类别的数量分布，BBoxVAE 接收标签集合以及每个类别的数量，生成每个物体的边界框。</p><p><strong>输出</strong>：CountVAE 输出每个类别的对象数量（例如，标签 1 的数量是 3），BBoxVAE 输出每个对象的边界框坐标（例如，x, y, w, h 值）。</p><p><strong>创新点</strong>：</p><ul><li>提出了一个基于VAE的生成模型，能够从标签集合中生成随机的场景布局。</li><li>模型分为两部分：CountVAE用于预测每个类别的对象数量，BBoxVAE用于预测每个对象的空间位置。</li><li>引入了基于VAE的自回归模型来生成多样的、合理的布局，解决了场景布局生成中的空间和数量关系建模问题。</li></ul><p><strong>任务类型</strong>：</p><h4 id="《Content-Aware-Generative-Modeling-of-Graphic-Design-Layouts》"><a href="#《Content-Aware-Generative-Modeling-of-Graphic-Design-Layouts》" class="headerlink" title="《Content-Aware Generative Modeling of Graphic Design Layouts》"></a>《Content-Aware Generative Modeling of Graphic Design Layouts》</h4><p><strong>输入</strong>：图像集合（多个图像，每个图像通过卷积神经网络（CNN）进行编码提取特征）、关键词（从文本内容中提取的摘要，使用RAKE方法提取）、设计属性（包括设计类别、文本比例和图像比例）</p><p><strong>输出</strong>：代表类别信息的单元格图像布局（60x45），6个类别，使用 3 维二进制向量进行编码。</p><p><strong>创新点</strong>：</p><ul><li>提出了第一个基于内容的图形设计布局生成方法，能够根据输入的视觉和文本内容及设计属性自动生成布局。</li><li>利用GAN生成符合内容的多样化布局，避免了传统方法中基于启发式规则的限制。</li><li>采用多模态嵌入网络处理视觉、文本和设计属性，增强了布局生成的灵活性和准确性。</li></ul><p><strong>任务类型</strong>：</p><h3 id="2021-2022：Transformer"><a href="#2021-2022：Transformer" class="headerlink" title="2021-2022：Transformer"></a>2021-2022：Transformer</h3><p>注：由于表格所能表达的信息有限，下面将采用论文列表+超链接到正文的形式。</p><h3 id="论文列表"><a href="#论文列表" class="headerlink" title="论文列表"></a>论文列表</h3><ol><li><a href="#CanvasVAE-Learning-to-Generate-Vector-Graphic-Documents">CanvasVAE: Learning to Generate Vector Graphic Documents</a></li><li><a href="#LayoutTransformer-Layout-Generation-and-Completion-with-Self-attention">LayoutTransformer: Layout Generation and Completion with Self-attention</a></li><li><a href="#Constrained-Graphic-Layout-Generation-via-Latent-Optimization">Constrained Graphic Layout Generation via Latent Optimization</a></li><li><a href="#Coarse-to-Fine-Generative-Modeling-for-Graphic-Layouts">Coarse-to-Fine Generative Modeling for Graphic Layouts</a></li><li><a href="#BLT-Bidirectional-Layout-Transformer-for-Controllable-Layout-Generation">BLT: Bidirectional Layout Transformer for Controllable Layout Generation</a></li><li><a href="#Geometry-Aligned-Variational-Transformer-for-Image-conditioned-Layout-Generation">Geometry Aligned Variational Transformer for Image-conditioned Layout Generation</a></li></ol><h4 id="CanvasVAE-Learning-to-Generate-Vector-Graphic-Documents"><a href="#CanvasVAE-Learning-to-Generate-Vector-Graphic-Documents" class="headerlink" title="CanvasVAE: Learning to Generate Vector Graphic Documents"></a>CanvasVAE: Learning to Generate Vector Graphic Documents</h4><p>——ICCV 2021</p><ul><li><p><strong>模型结构</strong>: 变分自编码器（VAE）结合Transformer模型</p></li><li><p><strong>输入</strong>: 各种图形元素的属性集合，如位置、大小、类型等</p></li><li><p><strong>输出</strong>: 生成的图形文档</p></li><li><p><strong>创新点</strong>: 提出了CanvasVAE框架，能生成和重建矢量图形文档</p></li><li><p><strong>任务类型</strong>: 矢量图形文档生成与重建</p></li></ul><h4 id="LayoutTransformer-Layout-Generation-and-Completion-with-Self-attention"><a href="#LayoutTransformer-Layout-Generation-and-Completion-with-Self-attention" class="headerlink" title="LayoutTransformer: Layout Generation and Completion with Self-attention"></a>LayoutTransformer: Layout Generation and Completion with Self-attention</h4><p>——ICCV 2021</p><ul><li><p><strong>模型结构</strong>: 使用自注意力的Layout Transformer模型</p></li><li><p><strong>输入</strong>: 布局信息和缺失部分</p></li><li><p><strong>输出</strong>: 生成的完整布局</p></li><li><p><strong>创新点</strong>: 提出了基于自注意力机制的布局生成和完成方法</p></li><li><p><strong>任务类型</strong>: 布局生成与补全</p></li></ul><h4 id="Constrained-Graphic-Layout-Generation-via-Latent-Optimization"><a href="#Constrained-Graphic-Layout-Generation-via-Latent-Optimization" class="headerlink" title="Constrained Graphic Layout Generation via Latent Optimization"></a>Constrained Graphic Layout Generation via Latent Optimization</h4><p>——ACMMM 2021</p><ul><li><strong>模型结构</strong>: 通过潜在优化约束生成图形布局</li><li><strong>输入</strong>: 布局元素及其约束信息</li><li><strong>输出</strong>: 生成的符合约束条件的布局</li><li><strong>创新点</strong>: 引入潜在优化机制来生成符合特定约束的图形布局</li><li><strong>任务类型</strong>: 布局生成与约束优化</li></ul><h4 id="Coarse-to-Fine-Generative-Modeling-for-Graphic-Layouts"><a href="#Coarse-to-Fine-Generative-Modeling-for-Graphic-Layouts" class="headerlink" title="Coarse-to-Fine Generative Modeling for Graphic Layouts"></a>Coarse-to-Fine Generative Modeling for Graphic Layouts</h4><p>——AAAI 2022</p><ul><li><strong>模型结构</strong>: 粗到精的生成模型，用于图形布局生成</li><li><strong>输入</strong>: 初步布局和其他辅助信息</li><li><strong>输出</strong>: 精细化的布局图</li><li><strong>创新点</strong>: 采用粗到精的生成方法，逐步优化布局</li><li><strong>任务类型</strong>: 图形布局生成</li></ul><h4 id="BLT-Bidirectional-Layout-Transformer-for-Controllable-Layout-Generation"><a href="#BLT-Bidirectional-Layout-Transformer-for-Controllable-Layout-Generation" class="headerlink" title="BLT: Bidirectional Layout Transformer for Controllable Layout Generation"></a>BLT: Bidirectional Layout Transformer for Controllable Layout Generation</h4><p>——ECCV 2022</p><ul><li><strong>模型结构</strong>: 双向Layout Transformer，用于可控布局生成</li><li><strong>输入</strong>: 布局元素及相关控制信息</li><li><strong>输出</strong>: 生成的布局</li><li><strong>创新点</strong>: 提出了双向Transformer架构，通过控制信息生成布局</li><li><strong>任务类型</strong>: 可控布局生成</li></ul><h4 id="Geometry-Aligned-Variational-Transformer-for-Image-conditioned-Layout-Generation"><a href="#Geometry-Aligned-Variational-Transformer-for-Image-conditioned-Layout-Generation" class="headerlink" title="Geometry Aligned Variational Transformer for Image-conditioned Layout Generation"></a>Geometry Aligned Variational Transformer for Image-conditioned Layout Generation</h4><p>——ACMMM 2022</p><ul><li><p><strong>模型结构</strong>: Variational Transformer用于图像条件下的布局生成。</p></li><li><p><strong>输入</strong>: 图像条件（如图像特征）与布局的初始框架</p></li><li><p><strong>输出</strong>: 生成的布局图</p></li><li><p><strong>创新点</strong>: 提出了一种几何对齐的变分Transformer模型，专为图像条件下的布局生成设计。</p></li><li><p><strong>任务类型</strong>: 图像条件下的布局生成</p></li></ul><h3 id="2022–2023：扩散模型与多模态条件"><a href="#2022–2023：扩散模型与多模态条件" class="headerlink" title="2022–2023：扩散模型与多模态条件"></a>2022–2023：扩散模型与多模态条件</h3><table><thead><tr><th>论文</th><th>年份</th><th>模型结构</th><th>输入</th><th>输出</th><th>创新点</th><th>任务类型</th></tr></thead><tbody><tr><td>DiffLayout</td><td>2022</td><td>Diffusion Model</td><td>随机初始化布局 + 约束条件</td><td>refined 布局 (N×d)</td><td>将布局建模为扩散去噪过程，支持多样性生成</td><td>通用</td></tr><tr><td>LayoutDM</td><td>2022</td><td>Diffusion + Transformer backbone</td><td>文本描述 + 元素属性</td><td>N×4 bounding box</td><td>文本条件控制布局生成</td><td>海报、广告</td></tr><tr><td>LTSim</td><td>2023</td><td>Diffusion + Simulation-based constraint</td><td>初始布局 + 几何约束</td><td>refined 布局</td><td>模拟用户约束，提升可控性</td><td>UI、交互式设计</td></tr></tbody></table><h3 id="2024–至今：多模态与交互式生成"><a href="#2024–至今：多模态与交互式生成" class="headerlink" title="2024–至今：多模态与交互式生成"></a>2024–至今：多模态与交互式生成</h3><h2 id="方法对比与分析"><a href="#方法对比与分析" class="headerlink" title="方法对比与分析"></a>方法对比与分析</h2><h3 id="模型结构演变"><a href="#模型结构演变" class="headerlink" title="模型结构演变"></a>模型结构演变</h3><ul><li>VAE&#x2F;GAN → Transformer → Diffusion  </li><li>各方法对比优缺点。</li></ul><h3 id="输入输出形式"><a href="#输入输出形式" class="headerlink" title="输入输出形式"></a>输入输出形式</h3><ul><li>输入从 <strong>元素属性</strong> 到 <strong>文本&#x2F;图像条件</strong>，再到 <strong>多模态指令</strong>。  </li><li>输出从 <strong>N×4 bounding box</strong> 到 <strong>token 序列化表示</strong>。</li></ul><h3 id="创新点聚焦"><a href="#创新点聚焦" class="headerlink" title="创新点聚焦"></a>创新点聚焦</h3><ul><li>分布建模方式（概率 &#x2F; 对抗 &#x2F; 扩散）。  </li><li>控制方式（几何约束、文本条件、多模态控制）。  </li><li>目标优化（合理性、多样性、可控性）。</li></ul><h3 id="任务类型支持"><a href="#任务类型支持" class="headerlink" title="任务类型支持"></a>任务类型支持</h3><ul><li>UI 界面生成（APP&#x2F;RICO dataset）。  </li><li>海报&#x2F;广告排版。  </li><li>图文混排（论文、杂志）。  </li><li>通用图文生成 pipeline 子模块。</li></ul><h2 id="趋势与思考"><a href="#趋势与思考" class="headerlink" title="趋势与思考"></a>趋势与思考</h2><ul><li><p>趋势：  </p><ul><li>模型越来越 <strong>可控</strong>（文本、图像、多模态条件）。  </li><li>从 <strong>单一布局生成</strong> → <strong>多模态联合建模</strong>。  </li><li>从 <strong>一次性生成</strong> → <strong>交互式、人机协同</strong>。</li></ul></li><li><p>我的观察：  </p><ul><li>哪些论文实用性强？  </li><li>哪些方法更适合 AIGC？  </li><li>对未来研究和落地的预测（如结合大语言模型、交互式设计工具）。</li></ul></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>回顾整体脉络：<strong>VAE → GAN → Transformer → Diffusion</strong>。  </li><li>提醒关注未来方向（多模态、交互式、泛化能力）。  </li><li>后续会继续更新调研，有兴趣的读者可以一起讨论。</li></ul><p>[LayoutGAN]: </p>]]></content>
    
    
    <categories>
      
      <category>论文调研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图像布局生成</tag>
      
      <tag>深度学习</tag>
      
      <tag>综述</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2025/08/07/hello-world/"/>
    <url>/2025/08/07/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
